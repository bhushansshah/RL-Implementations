# Jackâ€™s Car Rental â€“ Policy Iteration (Reinforcement Learning)

## ğŸ“– Problem Statement
This project implements **Example 4.2 (Jackâ€™s Car Rental)** from Sutton & Bartoâ€™s *Reinforcement Learning: An Introduction* (2nd Edition).

Jack manages **two car rental locations**.  
- Each day, customers arrive to rent cars.  
- If cars are available â†’ Jack earns **$10 per rental**.  
- If no cars are available â†’ demand is lost.  
- Cars are returned the next day (according to Poisson distributions).  
- Overnight, Jack may move cars between locations at a cost of **$2 per car moved**.  
- Each location can hold a **maximum of 20 cars**.  
- At most **5 cars can be moved per night**.  
- Discount factor: **Î³ = 0.9**.

The task is to formulate this as a **Markov Decision Process (MDP)** and solve it using **Policy Iteration** to find the optimal strategy for moving cars.

---

## âš™ï¸ Method
We use the **Policy Iteration algorithm**:
1. **Policy Evaluation**  
   Iteratively compute the state-value function \(V(s)\) under the current policy.
2. **Policy Improvement**  
   For each state, update the action (cars moved) that maximizes expected return.
3. **Repeat** until the policy converges to the optimal policy \(\pi^*\).

---

## ğŸ“Š Results

### Optimal Policy
The learned policy specifies **how many cars to move overnight** between locations, depending on the number of cars at each site.

![Policy](images/policy.png)

- **Red**: Move cars from Location 1 â†’ Location 2.  
- **Blue**: Move cars from Location 2 â†’ Location 1.  
- **Gray**: No movement.  

The policy balances car distribution to maximize rentals and minimize wasted returns.

---

### Optimal Value Function
The state-value function shows the **expected long-term return** for each state.

![Value Function](images/value_function.png)

- Maximum values occur **not at (20,20)** but around **balanced mid-range states (~10â€“15 cars each)**.  
- This reflects that too many cars â†’ wasted returns, too few cars â†’ lost rentals.  

---

## ğŸ“‚ Directory Structure
```
JACK'S CAR PROBLEM/                # Root project directory
â”‚
â”œâ”€â”€ algorithm/                     # Contains RL algorithms and policy definition
â”‚   â”œâ”€â”€ __init__.py                # Makes this a Python package
â”‚   â”œâ”€â”€ policy_iteration.py        # Policy Iteration algorithm (evaluation + improvement loop)
â”‚   â””â”€â”€ policy.py                  # Policy class (state â†’ action mapping, update logic)
â”‚
â”œâ”€â”€ env/                           # Environment definition for Jack's Car Rental
â”‚   â”œâ”€â”€ __init__.py                # Makes this a Python package
â”‚   â”œâ”€â”€ environment.py             # CarRentalEnv class (states, actions, rewards, transitions)
â”‚   â””â”€â”€ poisson_cache.py           # Utility for caching Poisson probabilities (performance optimization)
â”‚
â”œâ”€â”€ images/                        # Visualization outputs (plots for documentation/presentation)
â”‚   â”œâ”€â”€ policy.png                 # Heatmap of optimal policy (cars moved between locations)
â”‚   â””â”€â”€ value_function.png         # Heatmap of optimal state-value function
â”‚
â”œâ”€â”€ utils/                         # Utility functions (helpers for plotting, logging, etc.)
â”‚   â”œâ”€â”€ __init__.py                # Makes this a Python package
â”‚   â””â”€â”€ visualization.py           # Plotting functions for policy/value heatmaps
â”‚
â”œâ”€â”€ weights/                       # Stored run artifacts (learned weights/policies)
â”‚   â””â”€â”€ __init__.py                # Placeholder so directory is importable (can be optional)
â”‚
â”œâ”€â”€ main.py                        # Entry point to run the whole project (training + saving + plotting)
â”œâ”€â”€ requirements.txt               # Python dependencies needed to run the project
â””â”€â”€ test                           # Placeholder for tests (recommend renaming to tests/ with __init__.py)

```

---

## â–¶ï¸ Running the Project
```bash
python main.py   --policy_plot_file_path images/policy.png   --value_function_plot_file_path images/value_function.png   --policy_data_file_path weights/policy.npy   --value_data_file_path weights/value_function.npy
```

---

## âœ… Key Insights
- The optimal policy **does not hoard cars** â€” instead it keeps cars balanced and allows room for returns.  
- The value function demonstrates that **flexibility (space to accept returns)** can be more valuable than **having maximum cars in stock**.  
- This project shows how **dynamic programming** (policy iteration) solves real-world resource allocation problems in reinforcement learning.

---
