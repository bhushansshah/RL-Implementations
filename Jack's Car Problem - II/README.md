# Jackâ€™s Car Rental â€“ Policy Iteration (Reinforcement Learning)

## ğŸ“– Problem Statement
This project implements **Jackâ€™s Car Rental** from Sutton & Bartoâ€™s *Reinforcement Learning: An Introduction* (2nd Edition), using **Policy Iteration** to solve the resource allocation problem.

Jack manages **two car rental locations**.  
- Each day, customers arrive to rent cars.  
- If cars are available â†’ Jack earns **$10 per rental**.  
- If no cars are available â†’ demand is lost.  
- Cars are returned the next day (Poisson-distributed).  
- Overnight, Jack may move cars between locations at a cost.  
- Each location has limited capacity.  
- Discount factor: **Î³ = 0.9**.

We study **two versions** of the problem:  
1. **Problem I (Original)** â€“ Basic version as described in Example 4.2 of Sutton & Barto.  
2. **Problem II (Modified)** â€“ With additional constraints:  
   - Free move: One car from Location 1 â†’ Location 2 can be moved for free.  
   - Parking cost: Keeping **>10 cars overnight** at any location incurs a **$4 cost**.  

---

## âš™ï¸ Method
We solve both problems using **Policy Iteration**:
1. **Policy Evaluation**  
   Iteratively compute the state-value function \(V(s)\) under the current policy.  
2. **Policy Improvement**  
   Update the policy greedily with respect to expected returns.  
3. **Repeat** until convergence.

---

## ğŸ“Š Results

### Problem I â€“ Original Setup
The learned policy balances car distribution while accounting for move costs.  

**Optimal Policy (Problem I):**
![Policy](../Jack's%20Car%20Problem%20-%20I/images/policy.png)

- **Red** = Move cars from Location 1 â†’ Location 2  
- **Blue** = Move cars from Location 2 â†’ Location 1  
- **Gray** = No movement  

**Optimal Value Function (Problem I):**
![Value Function](../Jack's%20Car%20Problem%20-%20I/images/value_function.png)

- Highest values occur when cars are **balanced between locations**, not at maximum capacity.  
- Shows the tradeoff between keeping cars available vs. leaving room for returns.  

---

### Problem II â€“ Modified Setup
With the **free move** and **parking penalty**, the learned strategy changes noticeably:

**Optimal Policy (Problem II):**
![Policy](images/policy.png)

- There is a stronger **bias towards moving cars from Location 1 â†’ Location 2**, since the **first car is free**.  
- Policy avoids leaving **>10 cars** at either location, to prevent the **$4 parking penalty**.  

**Optimal Value Function (Problem II):**
![Value Function](images/value_function.png)

- The maximum expected returns shift further **towards balanced states with â‰¤10 cars** per location.   

---

## ğŸ“‚ Directory Structure
```
JACK'S CAR PROBLEM/                # Root project directory
â”‚
â”œâ”€â”€ algorithm/                     # Contains RL algorithms and policy definition
â”‚   â”œâ”€â”€ __init__.py                # Makes this a Python package
â”‚   â”œâ”€â”€ policy_iteration.py        # Policy Iteration algorithm (evaluation + improvement loop)
â”‚   â””â”€â”€ policy.py                  # Policy class (state â†’ action mapping, update logic)
â”‚
â”œâ”€â”€ env/                           # Environment definition for Jack's Car Rental
â”‚   â”œâ”€â”€ __init__.py                # Makes this a Python package
â”‚   â”œâ”€â”€ environment.py             # CarRentalEnv class (states, actions, rewards, transitions)
â”‚   â””â”€â”€ poisson_cache.py           # Utility for caching Poisson probabilities (performance optimization)
â”‚
â”œâ”€â”€ images/                        # Visualization outputs (plots for documentation/presentation)
â”‚   â”œâ”€â”€ policy.png                 # Heatmap of optimal policy (cars moved between locations)
â”‚   â””â”€â”€ value_function.png         # Heatmap of optimal state-value function
â”‚
â”œâ”€â”€ utils/                         # Utility functions (helpers for plotting, logging, etc.)
â”‚   â”œâ”€â”€ __init__.py                # Makes this a Python package
â”‚   â””â”€â”€ visualization.py           # Plotting functions for policy/value heatmaps
â”‚
â”œâ”€â”€ weights/                       # Stored run artifacts (learned weights/policies)
â”‚   â””â”€â”€ policy.npy                 # Storing learned policy as numpy array
â”‚   â””â”€â”€ value_function.npy         # Storing learned value function as numpy array
â”‚
â”œâ”€â”€ main.py                        # Entry point to run the whole project (training + saving + plotting)
â”œâ”€â”€ requirements.txt               # Python dependencies needed to run the project
â””â”€â”€ tests                          
â”‚   â””â”€â”€ checking_policy.ipynb      # Exploring the optimal policy.

```

---

## â–¶ï¸ Running the Project

1. Create and activate a virtual environment:
```bash
python3 -m venv env
source env/bin/activate
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Run policy iteration:
```bash
python3 main.py   --policy_plot_file_path images/policy.png   --value_function_plot_file_path images/value_function.png   --policy_data_file_path weights/policy.npy   --value_data_file_path weights/value_function.npy
```

---

## âœ… Key Insights
- **Problem I:** Optimal strategy keeps cars balanced while minimizing unnecessary moves.  
- **Problem II:** Free moves encourage bias towards Location 2, while the parking penalty forces states to stay under the **10-car limit** at both locations.  
- This demonstrates how small real-world nonlinearities (free perks, storage costs) can lead to significant changes in the **optimal RL policy**.  
